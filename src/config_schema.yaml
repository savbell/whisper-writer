# Global options that apply to all profiles
global_options:
  active_profiles:
    value: [Default]
    type: list
    description: "List of active profiles."
  input_backend:
    value: auto
    type: str
    description: "The input backend to use for detecting key presses. 'auto' will try to use the best available backend."
    options:
      - auto
      - evdev
      - pynput
  print_to_terminal:
    value: true
    type: bool
    description: "Set to true to print the script status and transcribed text to the terminal."
  show_status_window:
    value: true
    type: bool
    description: "Set to false to hide the status window during operation."
  noise_on_completion:
    value: false
    type: bool
    description: "Set to true to play a noise after the transcription has been typed out."

# Profile definitions
profiles:
  - name:
      value: Default
      type: str
      description: "The name of the profile."
    activation_key:
      value: ctrl+shift+space
      type: str
      description: "The keyboard shortcut to activate this profile. Separate keys with a '+'.\nYou can find the full list of supported keys in enums.py -> KeyCode(Enum).\nNot all input backends support all keys."
    backend_type:
      value: faster_whisper
      type: str
      description: "The transcription backend to use."
      options:
        - faster_whisper
        - openai
        - vosk
    backend:
      type: dict
      description: "Backend-specific options"
    recording_options:
      sound_device:
        value: null
        type: "int or null"
        description: "The numeric index of the sound device to use for recording. To find device numbers, run `python -m sounddevice`"
      sample_rate:
        value: 16000
        type: int
        description: "The sample rate in Hz to use for recording."
      recording_mode:
        value: continuous
        type: str
        description: "The recording mode to use."
        options:
          - continuous
          - voice_activity_detection
          - press_to_toggle
          - hold_to_record
      silence_duration:
        value: 900
        type: int
        description: "The duration in milliseconds to wait for silence before stopping the recording."
      min_duration:
        value: 200
        type: int
        description: "The minimum duration in milliseconds for a recording to be processed. Recordings shorter than this will be discarded."
    post_processing:
      writing_key_press_delay:
        value: 0.005
        type: float
        description: "The delay in seconds between each key press when writing the transcribed text."
      keyboard_simulator:
        value: pynput
        type: str
        description: "The method to use for simulating keyboard input.\npynput's support of Wayland is flawed.\nydotool and dotool require respective programs.\nuinput is the lightest (dependency-free) option."
        options:
          - pynput
          - ydotool
          - dotool
          - uinput
      enabled_scripts:
        value: []
        type: list
        description: "List of post-processing scripts to apply (in order). All scripts from the scripts folder will be displayed here. You can add new ones simply by coping add_trailing_space.py under a new name and editing it however you want."

# Available backend options
available_backends:
  faster_whisper:
    model:
      value: base
      type: str
      description: "The model to use for transcription. The larger models provide better accuracy but are slower."
      options:
        - tiny
        - tiny.en
        - base
        - base.en
        - small
        - small.en
        - medium
        - medium.en
        - large
        - large-v1
        - large-v2
        - large-v3
    compute_type:
      value: default
      type: str
      description: "The compute type to use for the local Whisper model."
      options:
        - default
        - float32
        - float16
        - int8
    device:
      value: auto
      type: str
      description: "The device to run the local Whisper model on. Use 'cuda' for NVIDIA GPUs, 'cpu' for CPU-only processing, or 'auto' to let the system automatically choose the best available device."
      options:
        - auto
        - cuda
        - cpu
    model_path:
      value: null
      type: dir_path
      description: "Path to the folder containing the model files. Leave empty to use online models."
    vad_filter:
      value: false
      type: bool
      description: "Set to true to use a voice activity detection (VAD) filter to remove silence from the recording."
    condition_on_previous_text:
      value: true
      type: bool
      description: "Set to true to use the previously transcribed text as a prompt for the next transcription request."
    temperature:
      value: 0.0
      type: float
      description: "Controls the randomness of the transcription output. Lower values make the output more focused and deterministic."
    initial_prompt:
      value: null
      type: str
      description: "A string used as an initial prompt to condition the transcription."
  openai:
    model:
      value: whisper-1
      type: str
      description: "The model to use for transcription. Currently only 'whisper-1' is available."
      options:
        - whisper-1
    base_url:
      value: https://api.openai.com/v1
      type: str
      description: "The base URL for the API. Can be changed to use a local API endpoint."
    api_key:
      value: null
      type: str
      description: "Your API key for the OpenAI API. Required for API usage."
    temperature:
      value: 0.0
      type: float
      description: "Controls the randomness of the transcription output. Lower values make the output more focused and deterministic."
    initial_prompt:
      value: null
      type: str
      description: "A string used as an initial prompt to condition the transcription."
  vosk:
    model_path:
      value: "./model"
      type: dir_path
      description: "Path to the folder containing the Vosk model files. Default is 'model' in the current directory."
    sample_rate:
      value: 16000
      type: int
      description: "Sample rate of the audio input. Vosk models are typically trained on 16kHz audio."
      options:
        - 8000
        - 16000
        - 22050
        - 44100
        - 48000
    use_streaming:
      value: false
      type: bool
      description: "If true, use streaming mode with partial results. If false, wait for complete audio before transcribing."
